{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import utils\n",
    "from model import MobileNetRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model\n",
    "model_parameters = ('mobilenetratio', utils.num_classes, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization for training\n",
    "# just normalization for validation\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'testing': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN (backbone) finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetRatio(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 64\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.5\n",
    "STEP_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (401771937.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3280/401771937.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for x in ['training', 'validation']}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# create pytorch datasets\n",
    "#datasets = {x: utils.HernitiaDataset(utils.dfs_path + '/' + x + '.pkl', return_ratio_frame_idx = True, transform = data_transforms[x])  \n",
    "#        for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'training': utils.HernitiaDataset(utils.dfs_path + '/training_no_temp_os.pkl', return_ratio_frame_idx = True, transform = data_transforms['training']),\n",
    "            'validation': utils.HernitiaDataset(utils.dfs_path + '/validation_no_temp.pkl', return_ratio_frame_idx = True, transform = data_transforms['validation'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloaders = {x: utils.DataLoader(dataset=datasets[x], batch_size=BATCH_SIZE, shuffle=True) for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# decay LR by a factor GAMMA every STEP_SIZE epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "----------\n",
      "610596/610596: [===============================>] - ETA 5.5sssss\n",
      "training Loss: 0.3543 Acc: 0.8861\n",
      "50216/50216: [===============================>] - ETA 1.6ssss\n",
      "validation Loss: 0.7494 Acc: 0.7689\n",
      "Epoch 2/6\n",
      "----------\n",
      "231616/610596: [============>...................] - ETA 2716.3s"
     ]
    }
   ],
   "source": [
    "utils.train_model(model = model, \n",
    "                    model_name = model.model_name,  #  name of the model which will be the name of the saved weights file within /weights\n",
    "                    dataloaders = dataloaders, \n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Freeze backbone - Unfreeze fc12 and retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetRatio(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(utils.weights_path + '/' + model.model_name + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze the linear layer processing the ratio\n",
    "model.freeze_backbone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.002\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.8\n",
    "STEP_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "datasets = {x: utils.HernitiaDataset(utils.dfs_path + '/' + x + '_no_temp.pkl', return_ratio_frame_idx = True, transform = data_transforms[x])  \n",
    "        for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloaders = {x: utils.DataLoader(dataset=datasets[x], batch_size=BATCH_SIZE, shuffle=True) for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# decay LR by a factor GAMMA every STEP_SIZE epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "164841/164841: [===============================>] - ETA 0.2sss\n",
      "training Loss: 0.1550 Acc: 0.9481\n",
      "50216/50216: [===============================>] - ETA 0.2sss\n",
      "validation Loss: 0.7855 Acc: 0.8065\n",
      "Epoch 2/10\n",
      "----------\n",
      "164841/164841: [===============================>] - ETA 0.2sss\n",
      "training Loss: 0.1490 Acc: 0.9495\n",
      "50216/50216: [===============================>] - ETA 0.2sss\n",
      "validation Loss: 0.8309 Acc: 0.8041\n",
      "Epoch 3/10\n",
      "----------\n",
      "164841/164841: [===============================>] - ETA 0.2sss\n",
      "training Loss: 0.1463 Acc: 0.9506\n",
      "50216/50216: [===============================>] - ETA 0.2sss\n",
      "validation Loss: 0.8382 Acc: 0.8011\n",
      "Epoch 4/10\n",
      "----------\n",
      "164841/164841: [===============================>] - ETA 0.2sss\n",
      "training Loss: 0.1447 Acc: 0.9518\n",
      "50216/50216: [===============================>] - ETA 0.2sss\n",
      "validation Loss: 0.8270 Acc: 0.8009\n",
      "Epoch 5/10\n",
      "----------\n",
      "164841/164841: [===============================>] - ETA 0.2sss\n",
      "training Loss: 0.1424 Acc: 0.9514\n",
      "50216/50216: [===============================>] - ETA 0.2sss\n",
      "validation Loss: 0.8288 Acc: 0.8013\n",
      "Epoch 6/10\n",
      "----------\n",
      " 47360/164841: [=========>......................] - ETA 428.4s"
     ]
    }
   ],
   "source": [
    "utils.train_model(model = model, \n",
    "                    model_name = model.model_name,  #  name of the model which will be the name of the saved weights file within /weights\n",
    "                    dataloaders = dataloaders, \n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetRatio(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload weights from finetuning\n",
    "model.load_state_dict(torch.load(utils.weights_path + '/' + model.model_name + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "dataset = utils.HernitiaDataset(utils.dfs_path + '/' + 'validation' + '_no_temp.pkl', return_ratio_frame_idx = True, transform = data_transforms['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloader = utils.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50216/50216: [===============================>] - ETA 0.2sss\n",
      "Loss: 0.7496 Acc: 0.8086\n"
     ]
    }
   ],
   "source": [
    "utils.evaluate_model(model, dataloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Kaggle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetRatio(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185728/185728: [===============================>] - ETA 0.2sss\n"
     ]
    }
   ],
   "source": [
    "utils.predict_kaggle(model = model, \n",
    "                     model_name = model.model_name, \n",
    "                     return_ratio_frame_idx = True, \n",
    "                     transform = data_transforms['testing'],\n",
    "                     predictions_name = model.model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Smooth prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " +2% test accuracy from what I have seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.smooth_predictions(predictions_name = model.model_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
