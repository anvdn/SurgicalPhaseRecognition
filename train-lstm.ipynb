{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import utils\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split train / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the split only if it has not already been done\n",
    "if not os.path.exists(utils.dfs_path + '/training_finetuning.pkl') or not os.path.exists(utils.dfs_path + '/validation_finetuning.pkl'):\n",
    "    # load all train videos (labelled videos)\n",
    "    all_train_videos = utils.get_train_test_video_names()['train']\n",
    "    all_train_labels = pd.read_pickle(utils.labels_path)\n",
    "\n",
    "    # define split\n",
    "    split = 0.8\n",
    "    np.random.seed(69)\n",
    "    train_videos = np.array(all_train_videos)[np.random.choice(len(all_train_videos), int(0.8 * len(all_train_videos)), replace=False)]\n",
    "    validation_videos = np.setdiff1d(all_train_videos, train_videos, assume_unique=False)\n",
    "    train_videos.sort()\n",
    "    validation_videos.sort()\n",
    "\n",
    "    # create two subdataframes for training and validation\n",
    "    training_df = all_train_labels.loc[all_train_labels['videoname'].isin(train_videos)]\n",
    "    validation_df = all_train_labels.loc[all_train_labels['videoname'].isin(validation_videos)]\n",
    "\n",
    "    training_df.to_pickle(utils.dfs_path + '/training_finetuning.pkl')\n",
    "    validation_df.to_pickle(utils.dfs_path + '/validation_finetuning.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.HernitiaModel(model_name = 'mobilenet_v2_lstm', num_classes = utils.num_classes, pretrained = True, skip_lstm = True).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2329756"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN (bottleneck) finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization for training\n",
    "# just normalization for validation\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.003\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.3\n",
    "STEP_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# decay LR by a factor GAMMA every STEP_SIZE epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "datasets = {x: utils.HernitiaDataset(utils.dfs_path + '/' + x + '.pkl', data_transforms[x])  for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloaders = {x: utils.DataLoader(dataset=datasets[x], batch_size=BATCH_SIZE, shuffle=True) for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train_model(model = model, \n",
    "                    model_name = model.model_name,  #  name of the model which will be the name of the saved weights file within /weights\n",
    "                    dataloaders = dataloaders, \n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pad with blank images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process consecutive frames by batch using our dataloaders, each batch loaded should only be composed of frames of a single video. A trick consists of padding each video with blank images at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "if not os.path.exists(utils.dfs_path + '/training_lstm.pkl') or not os.path.exists(utils.dfs_path + '/validation_lstm.pkl'):\n",
    "    for phase in ['training', 'validation']:\n",
    "        df = pd.read_pickle(utils.dfs_path + '/' + phase + '_finetuning.pkl')\n",
    "        for videoname in df['videoname'].unique():\n",
    "            # pad with blank images at the end of each video\n",
    "            # so as to only have number of frames multiple of BATCH_SIZE\n",
    "            # we can then process through the LSTM by batch without shuffling\n",
    "            num_frames = df[df.videoname == videoname].shape[0]\n",
    "            num_rows_to_add = (BATCH_SIZE - (num_frames % BATCH_SIZE)) % BATCH_SIZE\n",
    "            template_white_row = {'videoname': videoname, 'frame': 10000, 'label': -1}\n",
    "            white_rows_to_add = pd.DataFrame([template_white_row for _ in range(num_rows_to_add)])\n",
    "            df = pd.concat([df, white_rows_to_add], ignore_index=True)\n",
    "        df['sort'] = df['videoname'].str[-3:].astype(int)\n",
    "        # sort rows\n",
    "        df.sort_values(['sort', 'frame'],inplace=True, ascending=True)\n",
    "        df = df.drop('sort', axis=1)\n",
    "        # save df\n",
    "        df.to_pickle(utils.dfs_path + '/' + phase + '_lstm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Kaggle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing dataframe already in storage'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and save testing df\n",
    "utils.save_testing_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model\n",
    "model = models.mobilenet_v2(pretrained=True).to(utils.device)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, utils.num_classes, device = utils.device)\n",
    "model_name = 'mobilenet_v2'\n",
    "\n",
    "# data augmentation and normalization for training\n",
    "testing_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184003/184003: [===============================>] - ETA 0.7ssss\n"
     ]
    }
   ],
   "source": [
    "utils.predict_kaggle(model = model, \n",
    "                    model_name = model_name, # name of the model from which to load the weights within weights/\n",
    "                    transform = testing_transforms, \n",
    "                    predictions_name = model_name,\n",
    "                    batch_size = 64) # name of the csv file to which the predictions are saved within predictions/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
