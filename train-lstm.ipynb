{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import utils\n",
    "from model import HerniaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split train / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the split only if it has not already been done\n",
    "if not os.path.exists(utils.dfs_path + '/training_finetuning.pkl') or not os.path.exists(utils.dfs_path + '/validation_finetuning.pkl'):\n",
    "    # load all train videos (labelled videos)\n",
    "    all_train_videos = utils.get_train_test_video_names()['train']\n",
    "    all_train_labels = pd.read_pickle(utils.labels_path)\n",
    "\n",
    "    # define split\n",
    "    split = 0.8\n",
    "    np.random.seed(69)\n",
    "    train_videos = np.array(all_train_videos)[np.random.choice(len(all_train_videos), int(0.8 * len(all_train_videos)), replace=False)]\n",
    "    validation_videos = np.setdiff1d(all_train_videos, train_videos, assume_unique=False)\n",
    "    train_videos.sort()\n",
    "    validation_videos.sort()\n",
    "\n",
    "    # create two subdataframes for training and validation\n",
    "    training_df = all_train_labels.loc[all_train_labels['videoname'].isin(train_videos)]\n",
    "    validation_df = all_train_labels.loc[all_train_labels['videoname'].isin(validation_videos)]\n",
    "\n",
    "    training_df.to_pickle(utils.dfs_path + '/training_finetuning.pkl')\n",
    "    validation_df.to_pickle(utils.dfs_path + '/validation_finetuning.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model\n",
    "model_parameters = ('mobilenet_v2_lstm', utils.num_classes, True, 1, False, 16, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN (backbone) finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HerniaModel(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip lstm\n",
    "model.skip_lstm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization for training\n",
    "# just normalization for validation\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.002\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.5\n",
    "STEP_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# decay LR by a factor GAMMA every STEP_SIZE epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "datasets = {x: utils.HernitiaDataset(utils.dfs_path + '/' + x + '_finetuning.pkl', data_transforms[x])  for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloaders = {x: utils.DataLoader(dataset=datasets[x], batch_size=BATCH_SIZE, shuffle=True) for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "164841/164841: [===============================>] - ETA 0.9ssss\n",
      "training Loss: 0.4376 Acc: 0.8528\n",
      "50216/50216: [===============================>] - ETA 0.4sss\n",
      "validation Loss: 0.6508 Acc: 0.8003\n",
      "Training complete in 19m 6s\n",
      "Best val Acc: 0.800343\n"
     ]
    }
   ],
   "source": [
    "utils.train_model(model = model, \n",
    "                    model_name = model.model_name,  #  name of the model which will be the name of the saved weights file within /weights\n",
    "                    dataloaders = dataloaders, \n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model\n",
    "model = HerniaModel(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not skip lstm and freeze backbone\n",
    "model.skip_lstm = False\n",
    "model.freeze_backbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload weights from finetuning\n",
    "model.load_state_dict(torch.load(utils.weights_path + '/' + model.model_name + '.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pad with black images for training of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process consecutive frames by batch using our dataloaders, each batch loaded should only be composed of frames of a single video. A trick consists of padding each video with blank images at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "if not os.path.exists(utils.dfs_path + '/training_lstm.pkl') or not os.path.exists(utils.dfs_path + '/validation_lstm.pkl'):\n",
    "    for phase in ['training', 'validation']:\n",
    "        df = pd.read_pickle(utils.dfs_path + '/' + phase + '_finetuning.pkl')\n",
    "        for videoname in df['videoname'].unique():\n",
    "            # pad with black images at the end of each video\n",
    "            # so as to only have number of frames multiple of BATCH_SIZE\n",
    "            # we can then process through the LSTM by batch without shuffling\n",
    "            num_frames = df[df.videoname == videoname].shape[0]\n",
    "            num_rows_to_add = (BATCH_SIZE - (num_frames % BATCH_SIZE)) % BATCH_SIZE\n",
    "            template_white_row = {'videoname': videoname, 'frame': 10000, 'label': -1}\n",
    "            white_rows_to_add = pd.DataFrame([template_white_row for _ in range(num_rows_to_add)])\n",
    "            df = pd.concat([df, white_rows_to_add], ignore_index=True)\n",
    "        df['sort'] = df['videoname'].str[-12].astype(int) * 10000 + df['videoname'].str[-3:].astype(int)\n",
    "        # sort rows\n",
    "        df.sort_values(['sort', 'frame'],inplace=True, ascending=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df.drop(['sort', 'index'], axis=1)\n",
    "        # shuffle batches\n",
    "        index_list = np.array(df.index)\n",
    "        np.random.shuffle(np.reshape(index_list, (-1, BATCH_SIZE)))\n",
    "        shuffled_df = df.loc[index_list, :]\n",
    "        shuffled_df.reset_index(inplace=True)\n",
    "        shuffled_df = shuffled_df.drop(['index'], axis=1)\n",
    "        # save df\n",
    "        shuffled_df.to_pickle(utils.dfs_path + '/' + phase + '_lstm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Set training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization for training\n",
    "# just normalization for validation\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.005\n",
    "EPOCHS = 20\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.75\n",
    "STEP_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# decay LR by a factor GAMMA every STEP_SIZE epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "datasets = {x: utils.HernitiaDataset(utils.dfs_path + '/' + x + '_lstm.pkl', data_transforms[x])  for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloaders = {x: utils.DataLoader(dataset=datasets[x], batch_size=BATCH_SIZE, shuffle=False) for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 2.0076 Acc: 0.2466\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.7738 Acc: 0.3563\n",
      "Epoch 2/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.9323 Acc: 0.2875\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6177 Acc: 0.3998\n",
      "Epoch 3/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.8776 Acc: 0.3154\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.4467 Acc: 0.6072\n",
      "Epoch 4/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.8524 Acc: 0.3217\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5167 Acc: 0.4220\n",
      "Epoch 5/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.7930 Acc: 0.3616\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6770 Acc: 0.3974\n",
      "Epoch 6/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.7294 Acc: 0.4063\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6319 Acc: 0.4469\n",
      "Epoch 7/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.6586 Acc: 0.4394\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.7712 Acc: 0.4094\n",
      "Epoch 8/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.6105 Acc: 0.4590\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.8330 Acc: 0.3977\n",
      "Epoch 9/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.5695 Acc: 0.4741\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5881 Acc: 0.4734\n",
      "Epoch 10/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.5401 Acc: 0.4848\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5909 Acc: 0.4933\n",
      "Epoch 11/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.4885 Acc: 0.5019\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5177 Acc: 0.5066\n",
      "Epoch 12/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.4743 Acc: 0.5074\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6421 Acc: 0.4703\n",
      "Epoch 13/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.4444 Acc: 0.5166\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6014 Acc: 0.4851\n",
      "Epoch 14/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.4333 Acc: 0.5189\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5627 Acc: 0.4951\n",
      "Epoch 15/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.4083 Acc: 0.5289\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6769 Acc: 0.4791\n",
      "Epoch 16/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.3990 Acc: 0.5319\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6842 Acc: 0.4692\n",
      "Epoch 17/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.3776 Acc: 0.5398\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5324 Acc: 0.5280\n",
      "Epoch 18/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.3718 Acc: 0.5433\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5905 Acc: 0.4978\n",
      "Epoch 19/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.3616 Acc: 0.5416\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.6854 Acc: 0.4696\n",
      "Epoch 20/20\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.1sss\n",
      "training Loss: 1.3515 Acc: 0.5477\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.5355 Acc: 0.5184\n",
      "Training complete in 239m 11s\n",
      "Best val Acc: 0.607217\n"
     ]
    }
   ],
   "source": [
    "utils.train_model(model = model, \n",
    "                    model_name = model.model_name,  #  name of the model which will be the name of the saved weights file within /weights\n",
    "                    dataloaders = dataloaders, \n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Whole network finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model\n",
    "model = HerniaModel(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload weights from finetuning\n",
    "model.load_state_dict(torch.load(utils.weights_path + '/' + model.model_name + '.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Set training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization for training\n",
    "# just normalization for validation\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.0008\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.3\n",
    "STEP_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "# decay LR by a factor GAMMA every STEP_SIZE epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "datasets = {x: utils.HernitiaDataset(utils.dfs_path + '/' + x + '_lstm.pkl', data_transforms[x])  for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloaders = {x: utils.DataLoader(dataset=datasets[x], batch_size=BATCH_SIZE, shuffle=False) for x in ['training', 'validation']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.2ssss\n",
      "training Loss: 1.8947 Acc: 0.3164\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 2.0512 Acc: 0.2456\n",
      "Epoch 2/3\n",
      "----------\n",
      "165728/165728: [===============================>] - ETA 0.2sss\n",
      "training Loss: 1.4319 Acc: 0.5317\n",
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "validation Loss: 1.8941 Acc: 0.2812\n",
      "Epoch 3/3\n",
      "----------\n",
      "  3744/165728: [>...............................] - ETA 947.6s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_346/40335412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     num_epochs=EPOCHS)\n\u001b[0m",
      "\u001b[0;32m~/e6691-2022spring-assign2-HAAV-av3023-ha2605/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, dataloaders, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m    432\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_true_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_true_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# don't take into account padded white images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utils.train_model(model = model, \n",
    "                    model_name = model.model_name,  #  name of the model which will be the name of the saved weights file within /weights\n",
    "                    dataloaders = dataloaders, \n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Kaggle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save testing df\n",
    "utils.save_testing_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "if not os.path.exists(utils.dfs_path + '/testing_lstm.pkl'):\n",
    "    for phase in ['testing']:\n",
    "        df = pd.read_pickle(utils.dfs_path + '/testing.pkl')\n",
    "        for videoname in df['videoname'].unique():\n",
    "            # pad with blank images at the end of each video\n",
    "            # so as to only have number of frames multiple of BATCH_SIZE\n",
    "            # we can then process through the LSTM by batch without shuffling\n",
    "            num_frames = df[df.videoname == videoname].shape[0]\n",
    "            num_rows_to_add = (BATCH_SIZE - (num_frames % BATCH_SIZE)) % BATCH_SIZE\n",
    "            template_white_row = {'videoname': videoname, 'frame': 10000}\n",
    "            white_rows_to_add = pd.DataFrame([template_white_row for _ in range(num_rows_to_add)])\n",
    "            df = pd.concat([df, white_rows_to_add], ignore_index=True)\n",
    "        df['sort'] = df['videoname'].str[-12].astype(int) * 10000 + df['videoname'].str[-3:].astype(int)\n",
    "        # sort rows\n",
    "        df.sort_values(['sort', 'frame'],inplace=True, ascending=True)\n",
    "        df = df.drop('sort', axis=1)\n",
    "        # save df\n",
    "        df.to_pickle(utils.dfs_path + '/' + phase + '_lstm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild model\n",
    "model = HerniaModel(model_name = 'mobilenet_v2_lstm', \n",
    "                    num_classes = utils.num_classes, \n",
    "                    pretrained = True, \n",
    "                    num_layers_lstm = 2,\n",
    "                    bidirectional = False,\n",
    "                    hidden_size_lstm = 32,\n",
    "                    skip_lstm = False).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload weights from finetuning\n",
    "model.load_state_dict(torch.load(utils.weights_path + '/' + model.model_name + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization for training\n",
    "testing_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.predict_kaggle(model = model, \n",
    "                    model_name = model.model_name, # name of the model from which to load the weights within weights/\n",
    "                    transform = testing_transforms, \n",
    "                    predictions_name = model.model_name,\n",
    "                    batch_size = BATCH_SIZE) # name of the csv file to which the predictions are saved within predictions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HerniaModel(*model_parameters).to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip lstm\n",
    "model.skip_lstm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload weights from finetuning\n",
    "model.load_state_dict(torch.load(utils.weights_path + '/' + model.model_name + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# criterion is cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just normalization for validation\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch datasets\n",
    "dataset = utils.HernitiaDataset(utils.dfs_path + '/' + 'validation' + '_lstm.pkl', data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data loaders\n",
    "dataloader = utils.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50464/50464: [===============================>] - ETA 0.1sss\n",
      "Loss: 1.4467 Acc: 0.6072\n"
     ]
    }
   ],
   "source": [
    "utils.evaluate_model(model, dataloader, criterion)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
